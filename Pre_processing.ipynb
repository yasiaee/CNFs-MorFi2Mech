{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9634bf16-39a5-4317-89ad-2fb5326d9d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted data has been saved to formatted_data.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the raw MorFi data\n",
    "file_path = 'MorFi.xlsx'  \n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(file_path, sheet_name=xls.sheet_names[0])\n",
    "\n",
    "# Identify the row where data starts (Row 13 in the standard MorFi file)\n",
    "df_data = df.iloc[13:].reset_index(drop=True)\n",
    "\n",
    "# Rename columns \n",
    "df_data.columns = [\"Feature\", \"Value\"]\n",
    "\n",
    "# Drop empty rows\n",
    "df_data = df_data.dropna()\n",
    "\n",
    "# Fix encoding issues in feature names\n",
    "df_data[\"Feature\"] = df_data[\"Feature\"].str.replace(r'[ｵµ]', 'µ', regex=True)  # Fix µm\n",
    "df_data[\"Feature\"] = df_data[\"Feature\"].str.replace(r'ｲ', '²', regex=True)  # Fix ²\n",
    "df_data[\"Feature\"] = df_data[\"Feature\"].str.replace(r'ｰ', '°', regex=True)  # Fix °\n",
    "\n",
    "# Define Fiber_Length_Below_556, Fiber_Length_Above_556, Fiber_width_Below_19, Fiber_width_Above_19   \n",
    "feature_groups = {\n",
    "    \"Fiber_Length_Below_556\": [\"[200-289]\", \"[289-378]\", \"[378-467]\", \"[467-556]\"],\n",
    "    \"Fiber_Length_Above_556\": [\"[556-644]\", \"[644-733]\", \"[733-822]\", \"[822-911]\", \"[911-1000]\"],\n",
    "    \"Fiber_width_Below_19\": [\"[5-12]\", \"[12-19]\"],\n",
    "    \"Fiber_width_Above_19\": [\"[19-26]\", \"[26-33]\", \"[33-39]\", \"[39-46]\", \"[46-53]\", \"[53-60]\", \"[60-67]\", \"[67->]\"]\n",
    "}\n",
    "\n",
    "# Required features \n",
    "final_feature_order = [\n",
    "    \"Number of analysed fibres\",\n",
    "    \"Fibre content, millions/g of pulp\",\n",
    "    \"Fiber_Length_Below_556\",\n",
    "    \"Fiber_Length_Above_556\",\n",
    "    \"[1000->]\",\n",
    "    \"Mean fibre arithmetic length, µm\",\n",
    "    \"Mean length-weighted fibre length, µm\",\n",
    "    \"Fiber_width_Below_19\",\n",
    "    \"Fiber_width_Above_19\",\n",
    "    \"Mean fibre width, µm\",\n",
    "    \"Mean fibre coarseness, mg/m\",\n",
    "    \"Average kink number\",\n",
    "    \"Average kink angle, °\",\n",
    "    \"Kinked fibre content, %\",\n",
    "    \"Mean fibre curl index, %\",\n",
    "    \"MacroFibrillation index, %\",\n",
    "    \"Broken fibre content, %\",\n",
    "    \"Number of analysed fines\",\n",
    "    \"Fines content, millions/g of pulp\",\n",
    "    \"Fine content, % in area\",\n",
    "    \"Fine content, % in length\",\n",
    "    \"Fine content, % in length weighted in length\",\n",
    "    \"Mean fine area, µm²\",\n",
    "    \"Mean fine length, µm\"\n",
    "]\n",
    "\n",
    "# Initialize dictionary to store final values\n",
    "final_data = {}\n",
    "\n",
    "# Extract individual features\n",
    "for feature in final_feature_order:\n",
    "    value = df_data[df_data[\"Feature\"] == feature][\"Value\"].values\n",
    "    if len(value) > 0:\n",
    "        final_data[feature] = value[0]\n",
    "\n",
    "# Sum grouped features\n",
    "for new_feature, group in feature_groups.items():\n",
    "    total_value = df_data[df_data[\"Feature\"].isin(group)][\"Value\"].sum()\n",
    "    final_data[new_feature] = total_value\n",
    "\n",
    "# Convert dictionary to DataFrame in the correct order\n",
    "df_final = pd.DataFrame([final_data], columns=final_feature_order)\n",
    "\n",
    "# Save to CSV\n",
    "output_file = \"formatted_data.csv\"\n",
    "df_final.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Formatted data has been saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9985cb58-1a99-4f1c-bfdf-3f8c1d4519f9",
   "metadata": {},
   "source": [
    "Normalizing the data based on the traning and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ffc8b8f-eda2-439a-90a4-34e452c558e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized final data has been saved to normalized_final_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the training and validation dataset\n",
    "training_file = \"training_and_validation_data.csv\" \n",
    "df_train = pd.read_csv(training_file)\n",
    "\n",
    "# Load the formatted test data\n",
    "formatted_file = \"formatted_data.csv\"\n",
    "df_test = pd.read_csv(formatted_file)\n",
    "\n",
    "# Ensure both datasets have the same column order\n",
    "df_test = df_test[df_train.columns]  \n",
    "\n",
    "# Concatenate training and test data\n",
    "df_combined = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "# Convert all data to numeric \n",
    "df_combined = df_combined.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Perform Min-Max Normalization based on training and validation dataset\n",
    "for column in df_train.columns:\n",
    "    min_value = df_train[column].min()  # Get min from training data\n",
    "    max_value = df_train[column].max()  # Get max from training data\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if max_value != min_value:\n",
    "        df_combined[column] = (df_combined[column] - min_value) / (max_value - min_value)\n",
    "    else:\n",
    "        df_combined[column] = 0  # If min == max, set normalized value to 0\n",
    "\n",
    "# Extract the normalized final normalized data (last row)\n",
    "df_normalized_test = df_combined.iloc[-1:].reset_index(drop=True)\n",
    "\n",
    "# Save the normalized data to a new CSV file\n",
    "output_file = \"normalized_final_data.csv\"\n",
    "df_normalized_test.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Normalized final data has been saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5099b6dd-88c8-41ab-b739-354d503e75b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
